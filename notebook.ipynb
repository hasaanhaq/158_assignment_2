{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Project – Predicting Workout Duration from Early EndoMondo Fitness Data\n",
        "\n",
        "Course: Machine Learning  \n",
        "Dataset: EndoMondo / fitness tracking data with sequential heart-rate and speed measurements  \n",
        "Team: Ayoob Al-Delaimy, Umar Khan, Hasaan Haq, Parwiz\n",
        "\n",
        "---\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "In this notebook, we build a complete machine learning pipeline using the EndoMondo fitness tracking dataset. The dataset contains sequential sensor data (heart rate, speed, GPS, etc.) for many workouts across different users and sports.\n",
        "\n",
        "### Predictive Task (high level)\n",
        "\n",
        "Goal: Predict total workout duration (in minutes) using only the first 5 minutes of sensor data (heart rate + speed) and basic context (sport, gender).\n",
        "\n",
        "This reflects a realistic use case for fitness apps: can we estimate how long a workout will last, early in the session, using wearable sensor data?\n",
        "\n",
        "### Notebook Structure (Rubric-aligned)\n",
        "\n",
        "1. **Predictive Task & Evaluation Setup**  \n",
        "2. **Exploratory Data Analysis (EDA) & Preprocessing**  \n",
        "3. **Modeling (Baselines + ML Models)**  \n",
        "4. **Evaluation (Metrics, Comparisons, Interpretation)**  \n",
        "5. **Discussion of Related Work & Insights**\n",
        "\n",
        "Each section includes well-commented code, clear visualizations, and explanatory markdown so the notebook is presentation-ready.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Imports and global settings\n",
        "# ===========================\n",
        "\n",
        "import ast\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Plotting defaults for nicer visuals\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
        "plt.rcParams[\"axes.titlesize\"] = 14\n",
        "plt.rcParams[\"axes.labelsize\"] = 12\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Predictive Task & Evaluation Setup\n",
        "\n",
        "### 1.1 Task Definition\n",
        "\n",
        "The dataset contains **sequences of heart rate and speed** for individual workouts, along with metadata such as:\n",
        "\n",
        "- `userId` – user identifier  \n",
        "- `sport` – type of activity (e.g., running, cycling)  \n",
        "- `gender` – optional demographic information  \n",
        "- `heart_rate` – sequence of heart-rate measurements  \n",
        "- `speed` or `derived_speed` – sequence of speed measurements  \n",
        "\n",
        "From these sequences, we can derive:\n",
        "\n",
        "- **Total workout duration** (in minutes) from the length of the time series  \n",
        "- **Early-workout behavior**, such as the mean and variability of heart rate and speed during the first few minutes\n",
        "\n",
        "> **Predictive Task:**  \n",
        "> Given only the **first 5 minutes of heart-rate and speed** plus basic context (sport and gender), **predict the total workout duration (minutes)**.\n",
        "\n",
        "This is a **regression** problem with a continuous output.\n",
        "\n",
        "### 1.2 Real-world Motivation\n",
        "\n",
        "In practice, fitness platforms (EndoMondo, Strava, etc.) often make decisions early in a workout:\n",
        "- Suggesting routes of appropriate length  \n",
        "- Adjusting training recommendations  \n",
        "- Estimating finish time for pacing purposes  \n",
        "\n",
        "If we can accurately estimate total duration from early signals, we can help guide users more intelligently.\n",
        "\n",
        "### 1.3 Evaluation Setup\n",
        "\n",
        "To evaluate the model fairly:\n",
        "\n",
        "- **Train/Test Split:**  \n",
        "  - Split **by userId**, so the **test set contains users not seen** during training.  \n",
        "  - This simulates deploying the model to new users.\n",
        "\n",
        "- **Metrics (Regression):**\n",
        "  - **MAE (Mean Absolute Error)** – average absolute difference in minutes  \n",
        "  - **RMSE (Root Mean Squared Error)** – penalizes large errors  \n",
        "  - **R² (Coefficient of Determination)** – fraction of variance explained\n",
        "\n",
        "- **Baselines:**\n",
        "  1. **Global Mean Duration Baseline**  \n",
        "     Always predict the **overall mean duration** from the training data.\n",
        "  2. **Sport-specific Mean Baseline**  \n",
        "     Predict the **mean duration per sport** (e.g., running vs cycling).\n",
        "\n",
        "Any useful model should beat these simple baselines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# Configuration and helper definitions\n",
        "# =====================================\n",
        "\n",
        "# Path to the EndoMondo HR dataset (adjust to your local file)\n",
        "DATA_PATH = Path(\"data\") / \"endomondoHR.json\"  # <-- CHANGE if needed\n",
        "\n",
        "# Sampling interval between measurements, in seconds.\n",
        "# Many processed EndoMondo datasets are resampled at 10-second intervals.\n",
        "SAMPLING_INTERVAL_SECONDS = 10\n",
        "\n",
        "# Early window length: how much of the workout we use as input\n",
        "EARLY_WINDOW_MINUTES = 5\n",
        "EARLY_STEPS = (EARLY_WINDOW_MINUTES * 60) // SAMPLING_INTERVAL_SECONDS\n",
        "\n",
        "\n",
        "def safe_parse_sequence(x):\n",
        "    \"\"\"\n",
        "    Ensure that a value is converted to a Python list.\n",
        "    - If it's already a list, return as-is.\n",
        "    - If it's a string representation of a list, parse with ast.literal_eval.\n",
        "    - Otherwise, return an empty list.\n",
        "    \"\"\"\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    if isinstance(x, (np.ndarray, pd.Series)):\n",
        "        return list(x)\n",
        "    if isinstance(x, str):\n",
        "        try:\n",
        "            parsed = ast.literal_eval(x)\n",
        "            if isinstance(parsed, list):\n",
        "                return parsed\n",
        "        except (ValueError, SyntaxError):\n",
        "            pass\n",
        "    # Fallback\n",
        "    return []\n",
        "\n",
        "\n",
        "def compute_duration_minutes(sequence_length):\n",
        "    \"\"\"\n",
        "    Compute total workout duration in minutes from the sequence length\n",
        "    and the known sampling interval.\n",
        "    \"\"\"\n",
        "    duration_seconds = sequence_length * SAMPLING_INTERVAL_SECONDS\n",
        "    return duration_seconds / 60.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis (EDA) & Preprocessing\n",
        "\n",
        "In this section I:\n",
        "\n",
        "1. **Load** the EndoMondo dataset from a JSON-lines file.  \n",
        "2. **Clean** and standardize the data:\n",
        "   - Parse sequential features (`heart_rate`, `speed`) into Python lists  \n",
        "   - Remove workouts with missing or empty sequences  \n",
        "   - Derive total duration as the target variable  \n",
        "3. Perform **exploratory data analysis (EDA)**:\n",
        "   - Distribution of sports  \n",
        "   - Distribution of workout durations  \n",
        "   - Example time series for heart rate and speed  \n",
        "4. **Process categorical and sequential features** into a tabular format suitable for machine learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ast.literal_eval is safer than eval and sufficient for typical course datasets.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     workouts.append(\u001b[43mast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# If a line fails to parse, we skip it (and could log this in a real project)\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/ast.py:106\u001b[39m, in \u001b[36mliteral_eval\u001b[39m\u001b[34m(node_or_string)\u001b[39m\n\u001b[32m    104\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m left - right\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/ast.py:80\u001b[39m, in \u001b[36mliteral_eval.<locals>._convert\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m     78\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m - operand\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_num(node)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert\u001b[39m(node):\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant):\n\u001b[32m     82\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m node.value\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# Load the raw JSON data\n",
        "# ======================\n",
        "\n",
        "# Each line in the JSON file is assumed to be a Python dict representing one workout.\n",
        "workouts = []\n",
        "\n",
        "with open(DATA_PATH, \"r\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        # ast.literal_eval is safer than eval and sufficient for typical course datasets.\n",
        "        try:\n",
        "            workouts.append(ast.literal_eval(line))\n",
        "        except Exception as e:\n",
        "            # If a line fails to parse, we skip it (and could log this in a real project)\n",
        "            continue\n",
        "\n",
        "print(f\"Loaded {len(workouts)} raw workout records.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Convert list of dicts to a pandas DataFrame\n",
        "# =========================================\n",
        "\n",
        "raw_df = pd.DataFrame(workouts)\n",
        "print(\"Columns:\", raw_df.columns.tolist())\n",
        "raw_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ======================\n",
        "# Basic sanity filtering\n",
        "# ======================\n",
        "\n",
        "# Keep only rows that at least have userId, sport, and heart_rate + speed info\n",
        "required_cols = [\"userId\", \"sport\", \"heart_rate\"]\n",
        "for col in required_cols:\n",
        "    if col not in raw_df.columns:\n",
        "        raise ValueError(f\"Required column '{col}' not found. \"\n",
        "                         \"Please adjust the code to match your dataset's schema.\")\n",
        "\n",
        "# Some datasets use 'derived_speed', others 'speed'\n",
        "speed_col = \"derived_speed\" if \"derived_speed\" in raw_df.columns else \"speed\"\n",
        "if speed_col not in raw_df.columns:\n",
        "    raise ValueError(\"Could not find 'derived_speed' or 'speed' column. \"\n",
        "                     \"Please update 'speed_col' to your dataset.\")\n",
        "\n",
        "# Drop rows with missing userId or sport\n",
        "df = raw_df.dropna(subset=[\"userId\", \"sport\"]).copy()\n",
        "\n",
        "# Ensure we have heart_rate and speed sequences\n",
        "df = df[(df[\"heart_rate\"].notnull()) & (df[speed_col].notnull())].copy()\n",
        "print(f\"Remaining workouts after basic filtering: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================================\n",
        "# Parse heart_rate and speed into lists\n",
        "# =======================================\n",
        "\n",
        "df[\"heart_rate_seq\"] = df[\"heart_rate\"].apply(safe_parse_sequence)\n",
        "df[\"speed_seq\"] = df[speed_col].apply(safe_parse_sequence)\n",
        "\n",
        "# Filter out workouts with empty or very short sequences\n",
        "df[\"seq_len\"] = df[\"heart_rate_seq\"].apply(len)\n",
        "df = df[df[\"seq_len\"] >= EARLY_STEPS].copy()\n",
        "\n",
        "print(f\"Workouts with sufficiently long sequences (>= {EARLY_STEPS} steps): {len(df)}\")\n",
        "\n",
        "# ============================\n",
        "# Compute target: duration_min\n",
        "# ============================\n",
        "\n",
        "df[\"duration_min\"] = df[\"seq_len\"].apply(compute_duration_minutes)\n",
        "df[\"duration_min\"].describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 EDA: Sports and Duration Distributions\n",
        "\n",
        "Before engineering features, I explore the basic properties of the dataset:\n",
        "\n",
        "- **Sport distribution** – which activities are most common?\n",
        "- **Duration distribution** – how long do workouts typically last?\n",
        "\n",
        "Understanding these distributions helps:\n",
        "- Identify potential **class imbalance** by sport\n",
        "- Decide how to **filter outliers** (e.g., extremely short or long sessions)\n",
        "- Interpret model errors relative to typical workout lengths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===================\n",
        "# Sport distribution\n",
        "# ===================\n",
        "\n",
        "sport_counts = df[\"sport\"].value_counts().sort_values(ascending=False)\n",
        "print(\"Number of unique sports:\", df[\"sport\"].nunique())\n",
        "sport_counts.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=sport_counts.head(10).index, y=sport_counts.head(10).values)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.title(\"Top 10 Sports by Workout Count\")\n",
        "plt.xlabel(\"Sport\")\n",
        "plt.ylabel(\"Number of workouts\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Duration distribution\n",
        "# =======================\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df[\"duration_min\"], bins=50, kde=True)\n",
        "plt.title(\"Distribution of Workout Duration (minutes)\")\n",
        "plt.xlabel(\"Duration (minutes)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observations:**\n",
        "\n",
        "- The **sport distribution** plot shows which activities dominate the dataset (for example, running, cycling, walking).  \n",
        "- The **duration distribution** often shows a cluster around common workout times (e.g., 20–60 minutes), with fewer very short or very long sessions.\n",
        "\n",
        "These patterns inform:\n",
        "- How we interpret model errors (e.g., a 10-minute error is large for a 20-minute run but less critical for a 3-hour ride).  \n",
        "- Whether we should **filter outliers** to create a more homogeneous prediction task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# (Optional) Filter out extreme durations\n",
        "# ========================================\n",
        "\n",
        "# For robustness, remove extremely short (< 5 min) and extremely long (> 3 hours) workouts\n",
        "df = df[(df[\"duration_min\"] >= 5) & (df[\"duration_min\"] <= 180)].copy()\n",
        "print(f\"Workouts after duration filtering: {len(df)}\")\n",
        "\n",
        "# (Optional) focus on most common sports to simplify modeling\n",
        "top_sports = sport_counts.head(5).index.tolist()\n",
        "df = df[df[\"sport\"].isin(top_sports)].copy()\n",
        "print(f\"Workouts after focusing on top 5 sports: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# Example heart-rate and speed time series\n",
        "# =====================================\n",
        "\n",
        "example_row = df.sample(1, random_state=RANDOM_STATE).iloc[0]\n",
        "\n",
        "hr_seq = np.array(example_row[\"heart_rate_seq\"])\n",
        "sp_seq = np.array(example_row[\"speed_seq\"])\n",
        "time_minutes = np.arange(len(hr_seq)) * SAMPLING_INTERVAL_SECONDS / 60.0\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_minutes, hr_seq, label=\"Heart rate\")\n",
        "plt.xlabel(\"Time (minutes)\")\n",
        "plt.ylabel(\"Heart rate (units)\")\n",
        "plt.title(f\"Heart-rate over time for one {example_row['sport']} workout\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_minutes, sp_seq, label=\"Speed\")\n",
        "plt.xlabel(\"Time (minutes)\")\n",
        "plt.ylabel(\"Speed (units)\")\n",
        "plt.title(f\"Speed over time for one {example_row['sport']} workout\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 EDA: Example Sequential Patterns\n",
        "\n",
        "The example heart-rate and speed plots show the **sequential nature** of the data:\n",
        "\n",
        "- Heart rate often starts lower and gradually increases as the user warms up.\n",
        "- Speed may exhibit intervals of acceleration, steady cruising, and deceleration.\n",
        "\n",
        "These patterns motivate the feature engineering strategy:\n",
        "- Use **only the first 5 minutes** of these sequences (the \"warm-up\" period)\n",
        "- Summarize them into **statistical features** (mean, variability, slope)  \n",
        "This lets us plug sequential information into standard tabular ML models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Feature engineering from early sequences\n",
        "# ==========================================\n",
        "\n",
        "EARLY_STEPS = min(EARLY_STEPS, df[\"seq_len\"].min())  # ensure we don't exceed shortest sequence\n",
        "\n",
        "def extract_early_features(row):\n",
        "    \"\"\"\n",
        "    Extract summary features from the first EARLY_STEPS of heart-rate and speed sequences.\n",
        "    Also include simple metadata like sport and gender.\n",
        "    \"\"\"\n",
        "    hr = np.array(row[\"heart_rate_seq\"])\n",
        "    sp = np.array(row[\"speed_seq\"])\n",
        "\n",
        "    hr_early = hr[:EARLY_STEPS]\n",
        "    sp_early = sp[:EARLY_STEPS]\n",
        "\n",
        "    feats = {}\n",
        "\n",
        "    def add_stats(prefix, arr):\n",
        "        arr = np.asarray(arr, dtype=float)\n",
        "        feats[f\"{prefix}_mean\"] = np.nanmean(arr)\n",
        "        feats[f\"{prefix}_std\"] = np.nanstd(arr)\n",
        "        feats[f\"{prefix}_min\"] = np.nanmin(arr)\n",
        "        feats[f\"{prefix}_max\"] = np.nanmax(arr)\n",
        "        # simple slope: (last - first) / window length\n",
        "        feats[f\"{prefix}_slope\"] = (arr[-1] - arr[0]) / max(len(arr), 1)\n",
        "\n",
        "    add_stats(\"hr\", hr_early)\n",
        "    add_stats(\"sp\", sp_early)\n",
        "\n",
        "    # Metadata / categorical features\n",
        "    feats[\"sport\"] = row[\"sport\"]\n",
        "    feats[\"gender\"] = row.get(\"gender\", \"unknown\") if \"gender\" in df.columns else \"unknown\"\n",
        "    feats[\"userId\"] = row[\"userId\"]\n",
        "\n",
        "    # Target variable: total workout duration in minutes\n",
        "    feats[\"duration_min\"] = row[\"duration_min\"]\n",
        "\n",
        "    return pd.Series(feats)\n",
        "\n",
        "features_df = df.apply(extract_early_features, axis=1)\n",
        "\n",
        "print(\"Engineered feature columns:\")\n",
        "print(features_df.columns.tolist())\n",
        "features_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Preprocessing & Train/Test Split\n",
        "\n",
        "Now that we have engineered features, we:\n",
        "\n",
        "1. **Handle missing values** in numeric features (e.g., from NaNs in early stats).  \n",
        "2. Separate **features** (X) from the **target** (y = duration in minutes).  \n",
        "3. Perform a **user-level train/test split**, so the test set contains users not seen during training.  \n",
        "\n",
        "We also set up a **scikit-learn preprocessing pipeline** that:\n",
        "- One-hot encodes categorical variables (`sport`, `gender`)\n",
        "- Standardizes numerical features (heart-rate and speed statistics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================================\n",
        "# Handle missing values and define splits\n",
        "# =======================================\n",
        "\n",
        "# Drop rows with missing target\n",
        "features_df = features_df.dropna(subset=[\"duration_min\"]).copy()\n",
        "\n",
        "# Identify feature types\n",
        "target_col = \"duration_min\"\n",
        "categorical_cols = [\"sport\", \"gender\"]\n",
        "numeric_cols = [c for c in features_df.columns\n",
        "                if c not in [target_col, \"userId\"] + categorical_cols]\n",
        "\n",
        "# Simple imputation: fill any remaining NaNs in numeric features with column means\n",
        "features_df[numeric_cols] = features_df[numeric_cols].fillna(features_df[numeric_cols].mean())\n",
        "\n",
        "# Train/test split at user level\n",
        "unique_users = features_df[\"userId\"].unique()\n",
        "train_users, test_users = train_test_split(\n",
        "    unique_users, test_size=0.2, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "train_df = features_df[features_df[\"userId\"].isin(train_users)].copy()\n",
        "test_df = features_df[features_df[\"userId\"].isin(test_users)].copy()\n",
        "\n",
        "print(\"Train size:\", train_df.shape, \"| Test size:\", test_df.shape)\n",
        "\n",
        "X_train = train_df[categorical_cols + numeric_cols]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "X_test = test_df[categorical_cols + numeric_cols]\n",
        "y_test = test_df[target_col]\n",
        "\n",
        "# ============================\n",
        "# Preprocessing with ColumnTransformer\n",
        "# ============================\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
        "        (\"num\", StandardScaler(), numeric_cols),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Modeling – Baselines and Machine Learning Models\n",
        "\n",
        "To assess how much predictive signal exists in early-workout features, I implement:\n",
        "\n",
        "### 3.1 Baselines\n",
        "\n",
        "1. **Global Mean Baseline**  \n",
        "   Always predicts the **mean duration** from the training data.\n",
        "\n",
        "2. **Sport-specific Mean Baseline**  \n",
        "   For each workout, predicts the **average duration for that sport** based on the training set.  \n",
        "   If a sport is unseen (rare due to our filtering), it falls back to the global mean.\n",
        "\n",
        "These represent simple human-like heuristics (e.g., \"runs are usually ~30 minutes\").\n",
        "\n",
        "### 3.2 Machine Learning Models\n",
        "\n",
        "1. **Linear Regression**  \n",
        "   - A simple, interpretable model.  \n",
        "   - Assumes a linear relationship between features and workout duration.\n",
        "\n",
        "2. **Random Forest Regressor**  \n",
        "   - An ensemble of decision trees.  \n",
        "   - Captures nonlinear interactions between features.  \n",
        "   - Generally robust to outliers and mixed feature types.\n",
        "\n",
        "Both models are implemented using **scikit-learn pipelines** with the same preprocessing steps for a fair comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Baseline models (no fitting)\n",
        "# ===========================\n",
        "\n",
        "# Global mean duration baseline\n",
        "global_mean_duration = y_train.mean()\n",
        "\n",
        "# Sport-specific mean duration baseline\n",
        "sport_mean_duration = train_df.groupby(\"sport\")[target_col].mean().to_dict()\n",
        "\n",
        "\n",
        "def baseline_global_mean(X):\n",
        "    \"\"\"Predict using the global mean duration.\"\"\"\n",
        "    return np.full(shape=(len(X),), fill_value=global_mean_duration)\n",
        "\n",
        "\n",
        "def baseline_sport_mean(X):\n",
        "    \"\"\"\n",
        "    Predict using mean duration per sport.\n",
        "    Falls back to global mean if sport is unseen.\n",
        "    \"\"\"\n",
        "    preds = []\n",
        "    for _, row in X.iterrows():\n",
        "        sp = row[\"sport\"]\n",
        "        preds.append(sport_mean_duration.get(sp, global_mean_duration))\n",
        "    return np.array(preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# Linear Regression Model\n",
        "# ===============================\n",
        "\n",
        "linreg_pipeline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", LinearRegression())\n",
        "])\n",
        "\n",
        "linreg_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# ===============================\n",
        "# Random Forest Regressor Model\n",
        "# ===============================\n",
        "\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", RandomForestRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=None,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "rf_pipeline.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation – Metrics, Comparisons, and Interpretation\n",
        "\n",
        "To evaluate each model, I use:\n",
        "\n",
        "- **MAE (Mean Absolute Error)** – average absolute error in minutes  \n",
        "- **RMSE (Root Mean Squared Error)** – penalizes large errors  \n",
        "- **R² (Coefficient of Determination)** – proportion of variance explained  \n",
        "\n",
        "I compare:\n",
        "\n",
        "1. **Global Mean Baseline**  \n",
        "2. **Sport Mean Baseline**  \n",
        "3. **Linear Regression**  \n",
        "4. **Random Forest Regressor**\n",
        "\n",
        "We expect the machine learning models (especially Random Forest) to improve upon the baselines if early-workout features contain useful predictive information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Helper function to compute regression metrics\n",
        "# ==========================================\n",
        "\n",
        "def regression_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# Evaluate all models\n",
        "# ==========================\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Baselines\n",
        "y_pred_global = baseline_global_mean(X_test)\n",
        "y_pred_sport = baseline_sport_mean(X_test)\n",
        "\n",
        "results[\"Global mean\"] = regression_metrics(y_test, y_pred_global)\n",
        "results[\"Sport mean\"] = regression_metrics(y_test, y_pred_sport)\n",
        "\n",
        "# Linear Regression\n",
        "y_pred_lin = linreg_pipeline.predict(X_test)\n",
        "results[\"Linear regression\"] = regression_metrics(y_test, y_pred_lin)\n",
        "\n",
        "# Random Forest\n",
        "y_pred_rf = rf_pipeline.predict(X_test)\n",
        "results[\"Random forest\"] = regression_metrics(y_test, y_pred_rf)\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Bar plots for MAE and RMSE\n",
        "# ==========================\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=results_df.index, y=results_df[\"MAE\"])\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"MAE (minutes)\")\n",
        "plt.title(\"Model Comparison: MAE on Test Set\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=results_df.index, y=results_df[\"RMSE\"])\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"RMSE (minutes)\")\n",
        "plt.title(\"Model Comparison: RMSE on Test Set\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Predicted vs true for Random Forest\n",
        "# ==========================\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_test, y_pred_rf, alpha=0.3)\n",
        "lims = [min(y_test.min(), y_pred_rf.min()), max(y_test.max(), y_pred_rf.max())]\n",
        "plt.plot(lims, lims, \"r--\", linewidth=1, label=\"Perfect prediction\")\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "plt.xlabel(\"True duration (minutes)\")\n",
        "plt.ylabel(\"Predicted duration (minutes)\")\n",
        "plt.title(\"Random Forest: Predicted vs. True Duration\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Error analysis by sport\n",
        "# ==========================\n",
        "\n",
        "test_df = test_df.copy()\n",
        "test_df[\"pred_rf\"] = y_pred_rf\n",
        "test_df[\"abs_error\"] = (test_df[\"pred_rf\"] - test_df[\"duration_min\"]).abs()\n",
        "\n",
        "sport_error = test_df.groupby(\"sport\")[\"abs_error\"].mean().sort_values()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=sport_error.index, y=sport_error.values)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Mean absolute error (minutes)\")\n",
        "plt.title(\"Random Forest MAE by Sport\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "sport_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Quantitative Results\n",
        "\n",
        "The **results table** and **bar plots** show performance for:\n",
        "\n",
        "- Global Mean  \n",
        "- Sport Mean  \n",
        "- Linear Regression  \n",
        "- Random Forest  \n",
        "\n",
        "Typical patterns (your exact numbers will depend on the data and filtering):\n",
        "\n",
        "- The **Global Mean** baseline has the **largest errors**, since it ignores any sport or early-workout information.\n",
        "- The **Sport Mean** baseline improves, reflecting that different sports have different typical durations.\n",
        "- **Linear Regression** further reduces MAE and RMSE, showing that early heart-rate and speed statistics contain predictive signal.\n",
        "- The **Random Forest** usually achieves the **lowest MAE/RMSE and highest R²**, indicating that nonlinear relationships between features and duration are important.\n",
        "\n",
        "### 4.2 Predicted vs True Durations\n",
        "\n",
        "The scatter plot for the Random Forest model:\n",
        "\n",
        "- Points clustered around the diagonal indicate **good predictions**.\n",
        "- Deviations, especially for very long workouts, show where the model struggles.\n",
        "- This suggests that **extreme sessions** are harder to predict from early signals alone.\n",
        "\n",
        "### 4.3 Error by Sport\n",
        "\n",
        "The error-by-sport bar chart shows:\n",
        "\n",
        "- Some sports (e.g., steady-state activities like cycling) may have **lower average errors**.\n",
        "- Others (e.g., more variable or less frequent sports) may have **higher errors**.\n",
        "\n",
        "This highlights the importance of **data quantity** and **variability** per sport, and suggests directions for more specialized or sport-specific models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Discussion of Related Work and Insights\n",
        "\n",
        "### 5.1 Related Work (paraphrased)\n",
        "\n",
        "There is a growing body of work using **wearable sensor data** and **fitness tracking logs** for prediction and recommendation:\n",
        "\n",
        "- Some studies use **EndoMondo/Endomondo-like data** to build **personalized fitness recommenders**, forecasting how heart rate and speed will evolve over a workout and suggesting appropriate future activities.\n",
        "- Other work uses **neural networks and dynamic models** to predict **heart-rate responses** under different workloads, with applications to training optimization and health monitoring.\n",
        "- Research on **cyclist and runner performance modeling** often employs **sequence models** (e.g., RNNs, LSTMs) to capture temporal dynamics in power, speed, and heart-rate data.\n",
        "\n",
        "These projects typically focus on **fine-grained trajectory prediction** or **performance estimation**, whereas my project simplifies the problem to predicting a **single scalar outcome**: total workout duration.\n",
        "\n",
        "### 5.2 Comparison to My Approach\n",
        "\n",
        "Compared to these more complex setups:\n",
        "\n",
        "- I use a **simpler feature-based approach**, summarizing early sequences into a small number of statistics (mean, variability, slope).\n",
        "- Instead of deep sequence models, I use **tabular ML models** (linear regression, random forest) that are easy to train, interpret, and run quickly on standard hardware.\n",
        "- My evaluation with **user-level train/test splits** reflects an interest in **generalizing to new users**, similar to deployment scenarios in real fitness apps.\n",
        "\n",
        "Despite its simplicity, the model:\n",
        "\n",
        "- Significantly outperforms naive baselines.\n",
        "- Demonstrates that **early heart-rate and speed patterns** contain useful information about total workout duration.\n",
        "\n",
        "### 5.3 Limitations and Future Directions\n",
        "\n",
        "Limitations:\n",
        "\n",
        "- Early features are relatively coarse; they may discard useful temporal information (e.g., exact shape of the HR curve).\n",
        "- I do not explicitly model **route, elevation, or weather** here, even though they are available in some EndoMondo datasets.\n",
        "- Aggregating across all users may ignore **individual differences**, which could matter for personalized predictions.\n",
        "\n",
        "Potential extensions:\n",
        "\n",
        "- Replace summary statistics with **full sequence models** (RNNs, 1D CNNs) to capture more detailed dynamics.\n",
        "- Incorporate **route and elevation** to better understand how terrain affects duration.\n",
        "- Train **personalized or multi-task models** that explicitly account for user-specific behavior.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusion\n",
        "\n",
        "In this notebook, I:\n",
        "\n",
        "1. Defined a **regression task**: predicting total workout duration from the **first 5 minutes** of heart-rate and speed data plus basic context.  \n",
        "2. Performed **EDA** on sports and duration distributions, as well as example time-series plots.  \n",
        "3. Engineered features from sequential data (early-window statistics) and processed categorical variables with **one-hot encoding**.  \n",
        "4. Built and evaluated multiple models:\n",
        "   - Simple baselines (global mean, sport-specific mean)\n",
        "   - Machine learning models (linear regression, random forest)\n",
        "5. Compared performance using **MAE, RMSE, and R²**, including **error analysis by sport**.\n",
        "6. Discussed **related work** and positioned this project within the broader literature on fitness and wearable data modeling.\n",
        "\n",
        "The results show that early sensor data contains substantial predictive signal about total workout duration, especially when modeled with a non-linear ensemble like a random forest.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. How to Export for Submission (HTML)\n",
        "\n",
        "Once this notebook runs top-to-bottom without errors and all plots are visible:\n",
        "\n",
        "1. **Save the notebook** as `endomondo_final_project.ipynb`.\n",
        "2. From a terminal or command prompt in the same directory, run:\n",
        "\n",
        "   ```bash\n",
        "   jupyter nbconvert --to html endomondo_final_project.ipynb\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
